Binaların Enerji Verimliliği
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt 
import seaborn as sns
import pandas_profiling
from sklearn.preprocessing import Normalizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression, ElasticNet, Lasso
#import warning
#def ignore_warn(*args, **kwargs):
#    pass
#warnings.warn = ignore_warn 
data = pd.read_csv('ENB2012_data.csv')
data.head()
X1	X2	X3	X4	X5	X6	X7	X8	Y1	Y2
0	0.98	514.5	294.0	110.25	7.0	2	0.0	0	15.55	21.33
1	0.98	514.5	294.0	110.25	7.0	3	0.0	0	15.55	21.33
2	0.98	514.5	294.0	110.25	7.0	4	0.0	0	15.55	21.33
3	0.98	514.5	294.0	110.25	7.0	5	0.0	0	15.55	21.33
4	0.90	563.5	318.5	122.50	7.0	2	0.0	0	20.84	28.28
"""
Attribute Information:

X1 Relative Compactness

X2 Surface Area

X3 Wall Area

X4 Roof Area

X5 Overall Height

X6 Orientation

X7 Glazing Area

X8 Glazing Area Distribution

y1 Heating Load

y2 Cooling Load

"""
'\nAttribute Information:\n\nX1 Relative Compactness\n\nX2 Surface Area\n\nX3 Wall Area\n\nX4 Roof Area\n\nX5 Overall Height\n\nX6 Orientation\n\nX7 Glazing Area\n\nX8 Glazing Area Distribution\n\ny1 Heating Load\n\ny2 Cooling Load\n\n'
data.columns = ['relative_compactness', 'surface_area', 'wall_area', 'roof_area', 'overall_height',
                'orientation', 'glazing_area', 'glazing_area_distribution', 'heating_load', 'cooling_load']
data.head()
relative_compactness	surface_area	wall_area	roof_area	overall_height	orientation	glazing_area	glazing_area_distribution	heating_load	cooling_load
0	0.98	514.5	294.0	110.25	7.0	2	0.0	0	15.55	21.33
1	0.98	514.5	294.0	110.25	7.0	3	0.0	0	15.55	21.33
2	0.98	514.5	294.0	110.25	7.0	4	0.0	0	15.55	21.33
3	0.98	514.5	294.0	110.25	7.0	5	0.0	0	15.55	21.33
4	0.90	563.5	318.5	122.50	7.0	2	0.0	0	20.84	28.28
data.shape
(768, 10)
data.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 768 entries, 0 to 767
Data columns (total 10 columns):
 #   Column                     Non-Null Count  Dtype  
---  ------                     --------------  -----  
 0   relative_compactness       768 non-null    float64
 1   surface_area               768 non-null    float64
 2   wall_area                  768 non-null    float64
 3   roof_area                  768 non-null    float64
 4   overall_height             768 non-null    float64
 5   orientation                768 non-null    int64  
 6   glazing_area               768 non-null    float64
 7   glazing_area_distribution  768 non-null    int64  
 8   heating_load               768 non-null    float64
 9   cooling_load               768 non-null    float64
dtypes: float64(8), int64(2)
memory usage: 60.1 KB
data.describe().T
count	mean	std	min	25%	50%	75%	max
relative_compactness	768.0	0.764167	0.105777	0.62	0.6825	0.75	0.8300	0.98
surface_area	768.0	671.708333	88.086116	514.50	606.3750	673.75	741.1250	808.50
wall_area	768.0	318.500000	43.626481	245.00	294.0000	318.50	343.0000	416.50
roof_area	768.0	176.604167	45.165950	110.25	140.8750	183.75	220.5000	220.50
overall_height	768.0	5.250000	1.751140	3.50	3.5000	5.25	7.0000	7.00
orientation	768.0	3.500000	1.118763	2.00	2.7500	3.50	4.2500	5.00
glazing_area	768.0	0.234375	0.133221	0.00	0.1000	0.25	0.4000	0.40
glazing_area_distribution	768.0	2.812500	1.550960	0.00	1.7500	3.00	4.0000	5.00
heating_load	768.0	22.307201	10.090196	6.01	12.9925	18.95	31.6675	43.10
cooling_load	768.0	24.587760	9.513306	10.90	15.6200	22.08	33.1325	48.03
data.isnull().sum()
relative_compactness         0
surface_area                 0
wall_area                    0
roof_area                    0
overall_height               0
orientation                  0
glazing_area                 0
glazing_area_distribution    0
heating_load                 0
cooling_load                 0
dtype: int64
pandas_profiling.ProfileReport(data)
Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]
Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]
Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]
%matplotlib inline
plt.figure(figsize=(6,6))
sns.pairplot(data=data, y_vars=['cooling_load','heating_load'],
             x_vars=['relative_compactness', 'surface_area', 'wall_area', 'roof_area', 'overall_height',
                     'orientation', 'glazing_area', 'glazing_area_distribution',])
plt.show()
<Figure size 432x432 with 0 Axes>

corr_matrix = data.corr()
sns.clustermap(corr_matrix, annot=True, fmt='.2f')
plt.title('Correlation between features')
plt.show()

sns.pairplot(data, diag_kind='kde', markers ='+')
plt.show()

nr = Normalizer(copy=False)
X = data.drop(['heating_load','cooling_load'], axis=1)
X = nr.fit_transform(X)
y = data[['heating_load','cooling_load']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)
def evaluate(model, test_features, test_labels):
    predictions = model.predict(test_features)
    R2 = np.mean(r2_score(test_labels, predictions))
    print('R2 score = %.3f' % R2)
    return r2_score
dt_model = DecisionTreeRegressor(random_state=123)
dt_model.fit(X_train, y_train)
y_pred1 = dt_model.predict(X_test)
R2_before_dt= evaluate(dt_model, X_test, y_test)
R2 score = 0.966
parameters = {'max_depth' : [7,8,9],
              'min_samples_split': [16,17,18],
              'min_samples_leaf' : [6,7,8]}

dt_random = GridSearchCV(dt_model, parameters, cv=10)
dt_random.fit(X_train, y_train)
GridSearchCV(cv=10, estimator=DecisionTreeRegressor(random_state=123),
             param_grid={'max_depth': [7, 8, 9], 'min_samples_leaf': [6, 7, 8],
                         'min_samples_split': [16, 17, 18]})
dt_random.best_params_
{'max_depth': 7, 'min_samples_leaf': 8, 'min_samples_split': 18}
y_pred1_ = dt_random.best_estimator_.predict(X_test)
dt_best_random = dt_random.best_estimator_
R2_after_dt= evaluate(dt_best_random, X_test, y_test)
R2 score = 0.978
rf_model = RandomForestRegressor(random_state=123)
rf_model.fit(X_train, y_train)
y_pred2 = rf_model.predict(X_test)
R2_before_rf= evaluate(rf_model, X_test, y_test)
R2 score = 0.976
parameters = {'max_depth' : [6,7,8],
              'min_samples_split': [11,12,13],
              'min_samples_leaf' : [4,5,6],
              'n_estimators': [49,50,51]}
rf_random = GridSearchCV(rf_model, parameters, cv=10)
rf_random.fit(X_train, y_train)
GridSearchCV(cv=10, estimator=RandomForestRegressor(random_state=123),
             param_grid={'max_depth': [6, 7, 8], 'min_samples_leaf': [4, 5, 6],
                         'min_samples_split': [11, 12, 13],
                         'n_estimators': [49, 50, 51]})
rf_random.best_params_
{'max_depth': 7,
 'min_samples_leaf': 5,
 'min_samples_split': 11,
 'n_estimators': 51}
y_pred2_ = rf_random.best_estimator_.predict(X_test)
best_random_rf = rf_random.best_estimator_
R2_after_rf= evaluate(best_random_rf, X_test, y_test)
R2 score = 0.978
models = [LinearRegression, ElasticNet, Lasso, DecisionTreeRegressor, RandomForestRegressor]
for model in models:
    reg = model()
    reg.fit(X_train,y_train)
    pred = reg.predict(X_test)
    err = mean_squared_error(y_test, pred) ** .5
    print(f'RMSE of {model.__name__} model is: {err}')
    print(f'R2 value of {model.__name__} is: {np.mean(r2_score(y_test, pred))}')
    print('*'*50)
RMSE of LinearRegression model is: 3.072358724146067
R2 value of LinearRegression is: 0.9005854982778307
**************************************************
RMSE of ElasticNet model is: 9.827871851510723
R2 value of ElasticNet is: -0.00869348656326041
**************************************************
RMSE of Lasso model is: 9.830061488079147
R2 value of Lasso is: -0.00911925391189683
**************************************************
RMSE of DecisionTreeRegressor model is: 1.782740242032689
R2 value of DecisionTreeRegressor is: 0.9650240230895528
**************************************************
RMSE of RandomForestRegressor model is: 1.4694952052111383
R2 value of RandomForestRegressor is: 0.9762370711089126
**************************************************
 
